{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandor_daniel/miniconda3/envs/work/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import sys\n",
    "\n",
    "CAUSICA_FOLDER = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/'\n",
    "RESULT_DIR = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/results/'\n",
    "ROOT_DIR = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/'\n",
    "sys.path.append(ROOT_DIR)\n",
    "sys.path.append(CAUSICA_FOLDER)\n",
    "from causica.models.bayesdag.bayesdag_nonlinear import BayesDAGNonLinear\n",
    "from causica.datasets.variables import Variables, Variable\n",
    "from causica.datasets.dataset import Dataset, CausalDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_standard(file):\n",
    "    standard = pd.read_csv(file, sep='\\t', header=None)\n",
    "    standard.replace([f'G{i}' for i in range(10)], [f'G0{i}' for i in range(10)], inplace=True)\n",
    "    standard = standard.pivot(columns=[0], index=[1], values=[2])\n",
    "    np.fill_diagonal(standard.values, 0)\n",
    "    standard = standard.to_numpy()\n",
    "    return standard\n",
    "\n",
    "def remove_cycles_from_true_graph(true_graph):\n",
    "    G = nx.from_numpy_array(true_graph, create_using=nx.DiGraph())\n",
    "    for c in nx.simple_cycles(G):\n",
    "        true_graph[c[0], c[1]] = 0\n",
    "    return true_graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Bayes DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = np.loadtxt(f'gnw_example/Example_dream4_timeseries.tsv', skiprows=1)[:,1:]\n",
    "timeseries_split = np.split(timeseries, range(21,210,21), axis=0)\n",
    "\n",
    "ground_truth =load_standard(f'gnw_example/Example_goldstandard.tsv')\n",
    "# ground_truth = remove_cycles_from_true_graph(ground_truth)\n",
    "known_subgraph_mask = np.ones(ground_truth.shape)\n",
    "\n",
    "graph_args = {}\n",
    "graph_args['num_variables'] = timeseries.shape[1]\n",
    "graph_args['exp_edges'] = None\n",
    "graph_args['exp_edges_per_node'] = None\n",
    "graph_args['graph_type'] = None\n",
    "graph_args['seed'] = 123\n",
    "\n",
    "n_folds = len(timeseries_split)\n",
    "n_folds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving logs to /home/sandor_daniel/work/2024-05-07_active_bayesian_grn/results/train_output/summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/causica/models/bayesdag/bayesdag_nonlinear.py:238: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  W_adj = A_samples * vmap(self.ICGNN.get_weighted_adjacency)(params, buffers)\n",
      "/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/causica/models/bayesdag/bayesdag_nonlinear.py:239: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  predict = vmap(self.ICGNN.predict, in_dims=(0, 0, None, 0))(params, buffers, X, W_adj)# N x num_chain x D #chain x  N x 1  x D\n",
      "/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/causica/models/bayesdag/base_distributions.py:59: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  return vmap(self.log_prob_vmap)(z, self.mean_base, self.logscale_base)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found. Saving Checkpoint\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 115.44 MiB is free. Process 335144 has 30.32 GiB memory in use. Including non-PyTorch memory, this process has 1.29 GiB memory in use. Of the allocated memory 907.15 MiB is allocated by PyTorch, and 32.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m train_config_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# train_config_dict['standardize_data_mean'] = True\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# train_config_dict['standardize_data_std'] = True\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mbd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_config_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m dag_samples, is_dag \u001b[38;5;241m=\u001b[39m bd\u001b[38;5;241m.\u001b[39mget_adj_matrix(samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     37\u001b[0m bayes_dag_graphs \u001b[38;5;241m=\u001b[39m[dag_samples[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dag_samples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_dag[i]]\n",
      "File \u001b[0;32m~/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/causica/models/bayesdag/bayesdag_nonlinear.py:461\u001b[0m, in \u001b[0;36mBayesDAGNonLinear.run_train\u001b[0;34m(self, dataset, train_config_dict, report_progress_callback)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(dataset, CausalDataset)\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mhas_adjacency_data_matrix\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatent_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    459\u001b[0m     ):\n\u001b[0;32m--> 461\u001b[0m         adj_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m         adj_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/causica/models/bayesdag/bayesdag.py:573\u001b[0m, in \u001b[0;36mBayesDAG.evaluate_metrics\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: Dataset):\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03m    Evluate the metrics for a given dataset on the model (self)\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m        _type_: _description_\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m     adj_matrix, is_dag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_adj_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m     adj_true \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_adjacency_data_matrix()\n\u001b[1;32m    575\u001b[0m     subgraph_mask \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_known_subgraph_mask_matrix()\n",
      "File \u001b[0;32m~/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/causica/models/bayesdag/bayesdag_nonlinear.py:537\u001b[0m, in \u001b[0;36mBayesDAGNonLinear.get_adj_matrix\u001b[0;34m(self, samples, squeeze)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_adj_matrix\u001b[39m(\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    528\u001b[0m     samples: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m    529\u001b[0m     squeeze: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    530\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    531\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03m    Returns the adjacency matrix (or several) as a numpy array.\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03m        samples: Number of samples to return.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;124;03m        squeeze: Whether to squeeze the first dimension if samples == 1.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 537\u001b[0m     adj_matrix, is_dag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_adj_matrix_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m squeeze \u001b[38;5;129;01mand\u001b[39;00m samples \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    539\u001b[0m         adj_matrix \u001b[38;5;241m=\u001b[39m adj_matrix\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/causica/models/bayesdag/bayesdag_nonlinear.py:517\u001b[0m, in \u001b[0;36mBayesDAGNonLinear.get_adj_matrix_tensor\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    515\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data[indices]\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_posterior_p_sample(data\u001b[38;5;241m=\u001b[39minput_data, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dataset_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_size, interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_posterior_weights_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m p_vec\u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(samples):\n",
      "File \u001b[0;32m~/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/causica/models/bayesdag/bayesdag_nonlinear.py:365\u001b[0m, in \u001b[0;36mBayesDAGNonLinear._posterior_weights_sample\u001b[0;34m(self, data, dataset_size, num_samples)\u001b[0m\n\u001b[1;32m    363\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(ll_eltwise\u001b[38;5;241m+\u001b[39mtheta_prior\u001b[38;5;241m+\u001b[39msparse_loss)\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m#[]\u001b[39;00m\n\u001b[1;32m    364\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m--> 365\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/work/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/work/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/work/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 115.44 MiB is free. Process 335144 has 30.32 GiB memory in use. Including non-PyTorch memory, this process has 1.29 GiB memory in use. Of the allocated memory 907.15 MiB is allocated by PyTorch, and 32.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "vars = Variables([Variable(f'G{i}', True, 'continuous', lower=0, upper=1)\n",
    "         for i in range(1,timeseries.shape[1]+1)])\n",
    "\n",
    "bd_graphs = []\n",
    "\n",
    "for i in range(n_folds):\n",
    "\n",
    "    train_data = np.vstack(timeseries_split[:i] + timeseries_split[i+1:])\n",
    "    val_data = None\n",
    "    test_data = timeseries_split[i]\n",
    "\n",
    "    train_mask = np.ones(train_data.shape)\n",
    "    val_mask = None\n",
    "    test_mask = np.ones(test_data.shape)\n",
    "\n",
    "    dataset = CausalDataset(train_data, \n",
    "                        train_mask, \n",
    "                        remove_cycles_from_true_graph(ground_truth), \n",
    "                        known_subgraph_mask, \n",
    "                        None, \n",
    "                        None, \n",
    "                        val_data=val_data,  \n",
    "                        val_mask=val_mask,\n",
    "                        test_data=test_data,\n",
    "                        test_mask=test_mask,\n",
    "                        graph_args=graph_args)\n",
    "\n",
    "    bd = BayesDAGNonLinear('Model1', vars, RESULT_DIR, 'cuda:0', lambda_sparse=10, sparse_init=False)\n",
    "\n",
    "    train_config_dict = {}\n",
    "    train_config_dict['batch_size'] = 16\n",
    "    train_config_dict['max_epochs'] = 4\n",
    "    # train_config_dict['standardize_data_mean'] = True\n",
    "    # train_config_dict['standardize_data_std'] = True\n",
    "    bd.run_train(dataset, train_config_dict)\n",
    "    dag_samples, is_dag = bd.get_adj_matrix(samples=16)\n",
    "    bayes_dag_graphs =[dag_samples[i] for i in range(dag_samples.shape[0]) if is_dag[i]]\n",
    "    bd_graphs.extend(bayes_dag_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "442\n",
      "[[43, 143], [399, 3511]]\n",
      "186\n",
      "443\n",
      "[[37, 149], [406, 3504]]\n",
      "186\n",
      "441\n",
      "[[44, 142], [397, 3513]]\n",
      "186\n",
      "452\n",
      "[[37, 149], [415, 3495]]\n",
      "186\n",
      "466\n",
      "[[35, 151], [431, 3479]]\n",
      "186\n",
      "478\n",
      "[[51, 135], [427, 3483]]\n",
      "186\n",
      "493\n",
      "[[38, 148], [455, 3455]]\n",
      "186\n",
      "461\n",
      "[[43, 143], [418, 3492]]\n",
      "186\n",
      "517\n",
      "[[45, 141], [472, 3438]]\n",
      "186\n",
      "495\n",
      "[[53, 133], [442, 3468]]\n",
      "186\n",
      "450\n",
      "[[43, 143], [407, 3503]]\n",
      "186\n",
      "474\n",
      "[[47, 139], [427, 3483]]\n",
      "186\n",
      "447\n",
      "[[49, 137], [398, 3512]]\n",
      "186\n",
      "493\n",
      "[[59, 127], [434, 3476]]\n",
      "186\n",
      "455\n",
      "[[48, 138], [407, 3503]]\n",
      "186\n",
      "472\n",
      "[[47, 139], [425, 3485]]\n",
      "directed_shd: 563.5625\n",
      "undirected_shd: 563.5625\n",
      "directed_edge_f1_score: 0.1374563744331117\n",
      "pdag_f1_score: 0.13706570269747925\n",
      "pdag_shd: 587.1875\n"
     ]
    }
   ],
   "source": [
    "from utils import create_pdag, adjacency_to_edge_list, directed_shd, undirected_shd, directed_edge_f1_score, pdag_f1_score, pdag_shd, conf_matrix\n",
    "\n",
    "d_shds = []\n",
    "u_shds = []\n",
    "d_f1s = []\n",
    "p_f1s = []\n",
    "p_shds = []\n",
    "\n",
    "for g in bd_graphs:\n",
    "    pred = adjacency_to_edge_list(g)\n",
    "    \n",
    "    true_graph = adjacency_to_edge_list(ground_truth)\n",
    "\n",
    "    print(len(true_graph))\n",
    "    print(len(pred))\n",
    "    print(conf_matrix(true_graph, pred, len(vars)))\n",
    "\n",
    "    d_shds.append(directed_shd(true_graph, pred))\n",
    "    u_shds.append(undirected_shd(true_graph, pred))\n",
    "    d_f1s.append(directed_edge_f1_score(true_graph, pred))\n",
    "    true_pdag = create_pdag(remove_cycles_from_true_graph(ground_truth))\n",
    "    pred_pdag = create_pdag(g)\n",
    "    p_f1s.append(pdag_f1_score(true_pdag, pred_pdag))\n",
    "    p_shds.append(pdag_shd(true_pdag, pred_pdag))\n",
    "\n",
    "print(f'directed_shd: {np.mean(d_shds)}')\n",
    "print(f'undirected_shd: {np.mean(u_shds)}')\n",
    "print(f'directed_edge_f1_score: {np.mean(d_f1s)}')\n",
    "print(f'pdag_f1_score: {np.mean(p_f1s)}')\n",
    "print(f'pdag_shd: {np.mean(p_shds)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'directed_shd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdirected_shd\u001b[49m(true_graph, pred))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(undirected_shd(true_graph, pred))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'directed_shd' is not defined"
     ]
    }
   ],
   "source": [
    "print(directed_shd(true_graph, pred))\n",
    "print(undirected_shd(true_graph, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic GFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
