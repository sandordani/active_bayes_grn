{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandor_daniel/miniconda3/envs/work/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import sys\n",
    "\n",
    "CAUSICA_FOLDER = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/'\n",
    "RESULT_DIR = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/results/'\n",
    "ROOT_DIR = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/'\n",
    "GFLOW_DIR = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/jax-dag-gflownet'\n",
    "sys.path.append(ROOT_DIR)\n",
    "sys.path.append(CAUSICA_FOLDER)\n",
    "sys.path.append(GFLOW_DIR)\n",
    "from causica.models.bayesdag.bayesdag_nonlinear import BayesDAGNonLinear\n",
    "from causica.datasets.variables import Variables, Variable\n",
    "from causica.datasets.dataset import Dataset, CausalDataset\n",
    "\n",
    "from __future__ import annotations\n",
    "from dag_gflownet.env import GFlowNetDAGEnv\n",
    "from dag_gflownet.gflownet import DAGGFlowNet\n",
    "from dag_gflownet.utils.replay_buffer import ReplayBuffer\n",
    "from dag_gflownet.utils.factories import get_scorer\n",
    "from dag_gflownet.utils.gflownet import posterior_estimate\n",
    "from dag_gflownet.utils.metrics import expected_shd, expected_edges, threshold_metrics\n",
    "from dag_gflownet.utils import io\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from tqdm import trange\n",
    "from argparse import Namespace\n",
    "from utils import create_pdag, adjacency_to_edge_list, directed_shd, undirected_shd, directed_edge_f1_score, pdag_f1_score, pdag_shd, conf_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_standard(file):\n",
    "    standard = pd.read_csv(file, sep='\\t', header=None)\n",
    "    standard.replace([f'G{i}' for i in range(10)], [f'G0{i}' for i in range(10)], inplace=True)\n",
    "    standard = standard.pivot(columns=[0], index=[1], values=[2])\n",
    "    np.fill_diagonal(standard.values, 0)\n",
    "    standard = standard.to_numpy()\n",
    "    return standard\n",
    "\n",
    "def remove_cycles_from_true_graph(true_graph):\n",
    "    G = nx.from_numpy_array(true_graph, create_using=nx.DiGraph())\n",
    "    for c in nx.simple_cycles(G):\n",
    "        true_graph[c[0], c[1]] = 0\n",
    "    return true_graph\n",
    "\n",
    "timeseries = np.loadtxt(f'../gnw_example/Example_dream4_timeseries.tsv', skiprows=1)[:,1:]\n",
    "timeseries_split = np.split(timeseries, range(21,210,21), axis=0)\n",
    "\n",
    "ground_truth =load_standard(f'../gnw_example/Example_goldstandard.tsv')\n",
    "ground_truth = remove_cycles_from_true_graph(ground_truth)\n",
    "known_subgraph_mask = np.ones(ground_truth.shape)\n",
    "\n",
    "train_data = np.vstack(timeseries_split)\n",
    "val_data = None\n",
    "test_data = train_data\n",
    "\n",
    "train_mask = np.ones(train_data.shape)\n",
    "val_mask = None\n",
    "test_mask = np.ones(test_data.shape)\n",
    "\n",
    "graph_args = {}\n",
    "graph_args['num_variables'] = timeseries.shape[1]\n",
    "graph_args['exp_edges'] = None\n",
    "graph_args['exp_edges_per_node'] = None\n",
    "graph_args['graph_type'] = None\n",
    "graph_args['seed'] = 0\n",
    "\n",
    "dataset = CausalDataset(train_data, \n",
    "                        train_mask, \n",
    "                        ground_truth, \n",
    "                        known_subgraph_mask, \n",
    "                        None, \n",
    "                        None, \n",
    "                        val_data=val_data,  \n",
    "                        val_mask=val_mask,\n",
    "                        test_data=test_data,\n",
    "                        test_mask=test_mask,\n",
    "                        graph_args=graph_args)\n",
    "\n",
    "vars = Variables([Variable(f'G{i}', True, 'continuous', lower=0, upper=1)\n",
    "         for i in range(1,timeseries.shape[1]+1)])\n",
    "\n",
    "train_config_dict = {}\n",
    "train_config_dict['batch_size'] = 4\n",
    "train_config_dict['max_epochs'] = 10\n",
    "# bd.run_train(dataset, train_config_dict)\n",
    "\n",
    "def load_knockouts(file):\n",
    "    ko = pd.read_csv(file, sep='\\t', header=0)\n",
    "    ko = ko.to_numpy()[:,1:]\n",
    "    ko_dict = {i+1 : ko[i*21:(i+1)*21] for i in range(ko.shape[1])}\n",
    "    return ko_dict\n",
    "\n",
    "\n",
    "ko_dict = load_knockouts('../gnw_example/Example_knockout_timeseries.tsv')\n",
    "\n",
    "def eval_graphs(graphs, ground_truth, vars):\n",
    "    d_shds = []\n",
    "    u_shds = []\n",
    "    d_f1s = []\n",
    "    p_f1s = []\n",
    "    p_shds = []\n",
    "    nnzs = []\n",
    "\n",
    "    for g in graphs:\n",
    "        pred = adjacency_to_edge_list(g)\n",
    "        \n",
    "        true_graph = adjacency_to_edge_list(ground_truth)\n",
    "\n",
    "        print(len(true_graph))\n",
    "        print(len(pred))\n",
    "        print(conf_matrix(true_graph, pred, len(vars)))\n",
    "\n",
    "        d_shds.append(directed_shd(true_graph, pred))\n",
    "        u_shds.append(undirected_shd(true_graph, pred))\n",
    "        d_f1s.append(directed_edge_f1_score(true_graph, pred))\n",
    "        nnzs.append(len(pred))\n",
    "        true_pdag = create_pdag(remove_cycles_from_true_graph(ground_truth))\n",
    "        pred_pdag = create_pdag(g)\n",
    "        p_f1s.append(pdag_f1_score(true_pdag, pred_pdag))\n",
    "        p_shds.append(pdag_shd(true_pdag, pred_pdag))\n",
    "\n",
    "    with open(\"result_metrics.txt\", \"a\") as results:\n",
    "        results.write(\"Bayes DAG\\n\")\n",
    "        results.write(f'directed_shd: {np.mean(d_shds)}\\n')\n",
    "        results.write(f'undirected_shd: {np.mean(u_shds)}\\n')\n",
    "        results.write(f'directed_edge_f1_score: {np.mean(d_f1s)}\\n')\n",
    "        results.write(f'pdag_f1_score: {np.mean(p_f1s)}\\n')\n",
    "        results.write(f'pdag_shd: {np.mean(p_shds)}\\n')\n",
    "        results.write(f'nnz: {np.mean(nnzs)}\\n')\n",
    "        results.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_DAG_learning_framework import active_learning_procedure\n",
    "from DAG_estimator import BayesDAGEstimator\n",
    "\n",
    "bd_estimator = BayesDAGEstimator('BayesDAGEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('uniform', val_data, test_data, ko_dict, train_data, bd_estimator, pretrain_epochs=4)\n",
    "bd_graphs_unif = bd_estimator.sample_models()\n",
    "eval_graphs(bd_graphs_unif, ground_truth, vars)\n",
    "\n",
    "bd_estimator = BayesDAGEstimator('BayesDAGEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('entropy', val_data, test_data, ko_dict, train_data, bd_estimator, pretrain_epochs=4)\n",
    "bd_graphs_ee = bd_estimator.sample_models()\n",
    "eval_graphs(bd_graphs_ee, ground_truth, vars)\n",
    "\n",
    "bd_estimator = BayesDAGEstimator('BayesDAGEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('eces', val_data, test_data, ko_dict, train_data, bd_estimator, pretrain_epochs=4)\n",
    "bd_graphs_eces = bd_estimator.sample_models()\n",
    "eval_graphs(bd_graphs_eces, ground_truth, vars)\n",
    "\n",
    "bd_estimator = BayesDAGEstimator('BayesDAGEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('bald', val_data, test_data, ko_dict, train_data, bd_estimator, pretrain_epochs=4)\n",
    "bd_graphs_bald = bd_estimator.sample_models()\n",
    "eval_graphs(bd_graphs_bald, ground_truth, vars)\n",
    "\n",
    "bd_estimator = BayesDAGEstimator('BayesDAGEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('ebald', val_data, test_data, ko_dict, train_data, bd_estimator, pretrain_epochs=4)\n",
    "bd_graphs_ebald = bd_estimator.sample_models()\n",
    "eval_graphs(bd_graphs_ebald, ground_truth, vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DAG_estimator import GFlowDAGEstimator\n",
    "\n",
    "timeseries = np.loadtxt(f'gnw_example/Example_dream4_timeseries.tsv', skiprows=1)[:,1:]\n",
    "train_data = pd.DataFrame(data=timeseries)\n",
    "val_data =  None\n",
    "test_data =  train_data\n",
    "\n",
    "gflow_estimator = GFlowDAGEstimator('GFlowEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('uniform', val_data, test_data, ko_dict, train_data, gflow_estimator)\n",
    "gflow_graphs_unif = gflow_estimator.sample_models()\n",
    "eval_graphs(gflow_graphs_unif, ground_truth, vars)\n",
    "\n",
    "gflow_estimator = GFlowDAGEstimator('GFlowEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('entropy', val_data, test_data, ko_dict, train_data, gflow_estimator)\n",
    "gflow_graphs_ee = gflow_estimator.sample_models()\n",
    "eval_graphs(gflow_graphs_ee, ground_truth, vars)\n",
    "\n",
    "gflow_estimator = GFlowDAGEstimator('GFlowEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('eces', val_data, test_data, ko_dict, train_data, gflow_estimator)\n",
    "gflow_graphs_eces = gflow_estimator.sample_models()\n",
    "eval_graphs(gflow_graphs_eces, ground_truth, vars)\n",
    "\n",
    "gflow_estimator = GFlowDAGEstimator('GFlowEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('bald', val_data, test_data, ko_dict, train_data, gflow_estimator)\n",
    "gflow_graphs_bald = gflow_estimator.sample_models()\n",
    "eval_graphs(gflow_graphs_bald, ground_truth, vars)\n",
    "\n",
    "gflow_estimator = GFlowDAGEstimator('GFlowEstimator', vars, RESULT_DIR, 'cuda:0', graph_args)\n",
    "active_learning_procedure('ebald', val_data, test_data, ko_dict, train_data, gflow_estimator)\n",
    "gflow_graphs_ebald = gflow_estimator.sample_models()\n",
    "eval_graphs(gflow_graphs_ebald, ground_truth, vars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
