{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import h5py    \n",
    "import numpy as np    \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import sys\n",
    "\n",
    "CAUSICA_FOLDER = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/Project-BayesDAG/src/'\n",
    "RESULT_DIR = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/results/'\n",
    "ROOT_DIR = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/'\n",
    "gflow_dir = '/home/sandor_daniel/work/2024-05-07_active_bayesian_grn/jax-dag-gflownet'\n",
    "sys.path.append(ROOT_DIR)\n",
    "sys.path.append(CAUSICA_FOLDER)\n",
    "sys.path.append(gflow_dir)\n",
    "from causica.models.bayesdag.bayesdag_nonlinear import BayesDAGNonLinear\n",
    "from causica.datasets.variables import Variables, Variable\n",
    "from causica.datasets.dataset import Dataset, CausalDataset\n",
    "\n",
    "f = h5py.File('rnaseq_calico/ad_worm_aging.h5ad','r')   \n",
    "# for k in  f.keys():\n",
    "#     print(k, f[k].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_filter = f['obs']['annotate_name']['codes'][()] == 0\n",
    "col_filter = f['var']['gene_class']['codes'][()] == 0\n",
    "\n",
    "age_codes = f['obs']['timepoint']['codes'][()]\n",
    "age_categories = f['obs']['timepoint']['categories'][()]\n",
    "age_bytes = age_categories[age_codes[row_filter]]\n",
    "\n",
    "age = np.array(list(map(lambda a: float(str(a, encoding='utf-8')[1:]), age_bytes)))\n",
    "expression_counts = f['layers']['denoised'][()][row_filter][:,col_filter]\n",
    "genes = f['var']['gene_names'][()][col_filter]\n",
    "\n",
    "X = np.hstack([age[:,None], expression_counts])\n",
    "cols = np.append(['age'], [str(g, encoding='utf-8') for g in genes], axis=0)\n",
    "df_X = pd.DataFrame(X, columns=cols)\n",
    "# df_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesDAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[:int(X.shape[0]*0.8)]\n",
    "val_X = X[int(X.shape[0]*0.8):int(X.shape[0]*0.9)]\n",
    "test_X = X[int(X.shape[0]*0.9):]\n",
    "\n",
    "train_mask = np.ones(train_X.shape)\n",
    "val_mask = np.ones(val_X.shape)\n",
    "test_mask = np.ones(test_X.shape)\n",
    "\n",
    "graph_args = {}\n",
    "graph_args['num_variables'] = X.shape[1]\n",
    "graph_args['exp_edges'] = None\n",
    "graph_args['exp_edges_per_node'] = None\n",
    "graph_args['graph_type'] = None\n",
    "graph_args['seed'] = 0\n",
    "\n",
    "\n",
    "dataset = Dataset(train_X, train_mask, \n",
    "                        val_data=val_X, val_mask=val_mask, \n",
    "                        test_data=test_X, test_mask=test_mask,\n",
    "                        graph_args=graph_args)\n",
    "\n",
    "train_config_dict = {}\n",
    "train_config_dict['batch_size'] = 16\n",
    "train_config_dict['max_epochs'] = 1\n",
    "\n",
    "train_rounds = 3\n",
    "dag_log = []\n",
    "\n",
    "name = 'worm_aging_DAG'\n",
    "vars = Variables([Variable('age', True, 'continuous', lower=1., upper=15.)] + [Variable(str(g, encoding='utf-8'), True, 'continuous', lower=0, upper=10e3) for g in genes])\n",
    "device = 'cuda:0'\n",
    "\n",
    "\n",
    "# for i in range(train_rounds):\n",
    "#     bd = BayesDAGNonLinear(name, vars, RESULT_DIR, device)\n",
    "#     bd.run_train(dataset, train_config_dict)\n",
    "#     Ws, _, _ = bd.get_weighted_adj_matrix(samples=4)\n",
    "#     dag_log.append(Ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.from_numpy_array(np.abs(dag_log[0][0].cpu().numpy()) > 0.4, create_using=nx.DiGraph())\n",
    "# G = nx.relabel_nodes(G, {i:c for i, c in enumerate(cols)})\n",
    "\n",
    "# cmap = ['green'] + ['lightblue' for i in range(1, len(cols))]\n",
    "\n",
    "# for i, gene in enumerate([str(g, encoding='utf-8') for g in genes]):\n",
    "#     if G.has_edge('age', gene) or G.has_edge(gene, 'age') or np.any([G.has_edge(p, gene) for p in G.predecessors('age')]):\n",
    "#         cmap[i+1] = 'lightgreen'\n",
    "\n",
    "\n",
    "# nx.draw(G, node_color=cmap, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dag_gflownet.env import GFlowNetDAGEnv\n",
    "from dag_gflownet.gflownet import DAGGFlowNet\n",
    "from dag_gflownet.utils.replay_buffer import ReplayBuffer\n",
    "from dag_gflownet.utils.factories import get_scorer\n",
    "from dag_gflownet.utils.gflownet import posterior_estimate\n",
    "from dag_gflownet.utils.metrics import expected_shd, expected_edges, threshold_metrics\n",
    "from dag_gflownet.utils import io\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from tqdm import trange\n",
    "from argparse import Namespace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gflownet = DAGGFlowNet()\n",
    "# optimizer = optax.adam(0.01)\n",
    "\n",
    "# prefill = 1000\n",
    "# num_iterations = 10000\n",
    "# batch_size = 32\n",
    "\n",
    "# scorer_args = Namespace(prior='uniform', graph='calico', data=df_X, prior_kwargs={}, scorer_kwargs={})\n",
    "# scorer, data, graph = get_scorer(scorer_args)\n",
    "# key = jax.random.PRNGKey(123)\n",
    "# key, subkey = jax.random.split(key)\n",
    "\n",
    "\n",
    "# env = GFlowNetDAGEnv(\n",
    "#     num_envs=8,\n",
    "#     scorer=scorer\n",
    "# )\n",
    "\n",
    "# replay = ReplayBuffer(\n",
    "#     10000,\n",
    "#     num_variables=env.num_variables\n",
    "# )\n",
    "\n",
    "\n",
    "# exploration_schedule = jax.jit(optax.linear_schedule(\n",
    "#     init_value=jnp.array(0.),\n",
    "#     end_value=jnp.array(1. - 0.1),\n",
    "#     transition_steps=num_iterations // 2,\n",
    "#     transition_begin=prefill,\n",
    "# ))\n",
    "\n",
    "# params, state = gflownet.init(\n",
    "#         subkey,\n",
    "#         optimizer,\n",
    "#         replay.dummy['adjacency'],\n",
    "#         replay.dummy['mask']\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training loop\n",
    "# indices = None\n",
    "# observations = env.reset()\n",
    "\n",
    "\n",
    "\n",
    "# with trange(prefill + num_iterations, desc='Training') as pbar:\n",
    "#     for iteration in pbar:\n",
    "#         # Sample actions, execute them, and save transitions in the replay buffer\n",
    "#         epsilon = exploration_schedule(iteration)\n",
    "#         actions, key, logs = gflownet.act(params.online, key, observations, epsilon)\n",
    "#         next_observations, delta_scores, dones, _ = env.step(np.asarray(actions))\n",
    "#         indices = replay.add(\n",
    "#             observations,\n",
    "#             actions,\n",
    "#             logs['is_exploration'],\n",
    "#             next_observations,\n",
    "#             delta_scores,\n",
    "#             dones,\n",
    "#             prev_indices=indices\n",
    "#         )\n",
    "#         observations = next_observations\n",
    "\n",
    "#         if iteration >= prefill:\n",
    "#             # Update the parameters of the GFlowNet\n",
    "#             samples = replay.sample(batch_size=batch_size)\n",
    "#             params, state, logs = gflownet.step(params, state, samples)\n",
    "\n",
    "#             pbar.set_postfix(loss=f\"{logs['loss']:.2f}\", epsilon=f\"{epsilon:.2f}\")\n",
    "\n",
    "# # Evaluate the posterior estimate\n",
    "# posterior, _ = posterior_estimate(\n",
    "#     gflownet,\n",
    "#     params.online,\n",
    "#     env,\n",
    "#     key,\n",
    "#     num_samples=1000,\n",
    "#     desc='Sampling from posterior'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"results/gflow/gflow_posterior\", posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.1\n",
    "# dag = (np.mean(posterior, axis=0) > threshold)\n",
    "\n",
    "# G = nx.from_numpy_array(np.abs(dag), create_using=nx.DiGraph())\n",
    "# G = nx.relabel_nodes(G, {i:c for i, c in enumerate(cols)})\n",
    "\n",
    "# cmap = ['green'] + ['lightblue' for i in range(1, len(cols))]\n",
    "\n",
    "# for i, gene in enumerate([str(g, encoding='utf-8') for g in genes]):\n",
    "#     if G.has_edge('age', gene) or G.has_edge(gene, 'age') or np.any([G.has_edge(p, gene) for p in G.predecessors('age')]):\n",
    "#         cmap[i+1] = 'lightgreen'\n",
    "\n",
    "\n",
    "# nx.draw(G, node_color=cmap, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFN DREAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_standard(file):\n",
    "    standard = pd.read_csv(file, sep='\\t', header=None)\n",
    "    standard.replace([f'G{i}' for i in range(10)], [f'G0{i}' for i in range(10)], inplace=True)\n",
    "    standard = standard.pivot(columns=[0], index=[1], values=[2])\n",
    "    np.fill_diagonal(standard.values, 0)\n",
    "    standard = standard.to_numpy()\n",
    "    return standard\n",
    "\n",
    "def remove_cycles_from_true_graph(true_graph):\n",
    "    G = nx.from_numpy_array(true_graph, create_using=nx.DiGraph())\n",
    "    for c in nx.simple_cycles(G):\n",
    "        true_graph[c[0], c[1]] = 0\n",
    "    return true_graph\n",
    "\n",
    "\n",
    "ground_truth =load_standard(f'gnw_example/Example_goldstandard.tsv')\n",
    "ground_truth = remove_cycles_from_true_graph(ground_truth)\n",
    "known_subgraph_mask = np.ones(ground_truth.shape)\n",
    "\n",
    "timeseries = np.loadtxt(f'gnw_example/Example_dream4_timeseries.tsv', skiprows=1)[:,1:]\n",
    "train_data = pd.DataFrame(data=timeseries[:-42])\n",
    "val_data =  pd.DataFrame(data=timeseries[-21:])\n",
    "test_data =  pd.DataFrame(data=timeseries[-42:-21])\n",
    "\n",
    "df_X = train_data\n",
    "\n",
    "gflownet = DAGGFlowNet()\n",
    "optimizer = optax.adam(0.01)\n",
    "\n",
    "prefill = 1000\n",
    "num_iterations = 10000\n",
    "batch_size = 32\n",
    "\n",
    "scorer_args = Namespace(prior='uniform', graph='calico', data=df_X, prior_kwargs={}, scorer_kwargs={})\n",
    "scorer, data, graph = get_scorer(scorer_args)\n",
    "key = jax.random.PRNGKey(123)\n",
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "\n",
    "env = GFlowNetDAGEnv(\n",
    "    num_envs=8,\n",
    "    scorer=scorer\n",
    ")\n",
    "\n",
    "replay = ReplayBuffer(\n",
    "    10000,\n",
    "    num_variables=env.num_variables\n",
    ")\n",
    "\n",
    "\n",
    "exploration_schedule = jax.jit(optax.linear_schedule(\n",
    "    init_value=jnp.array(0.),\n",
    "    end_value=jnp.array(1. - 0.1),\n",
    "    transition_steps=num_iterations // 2,\n",
    "    transition_begin=prefill,\n",
    "))\n",
    "\n",
    "params, state = gflownet.init(\n",
    "        subkey,\n",
    "        optimizer,\n",
    "        replay.dummy['adjacency'],\n",
    "        replay.dummy['mask']\n",
    "    )\n",
    "\n",
    "# Training loop\n",
    "indices = None\n",
    "observations = env.reset()\n",
    "\n",
    "\n",
    "\n",
    "with trange(prefill + num_iterations, desc='Training') as pbar:\n",
    "    for iteration in pbar:\n",
    "        # Sample actions, execute them, and save transitions in the replay buffer\n",
    "        epsilon = exploration_schedule(iteration)\n",
    "        print(epsilon)\n",
    "        actions, key, logs = gflownet.act(params.online, key, observations, epsilon)\n",
    "        next_observations, delta_scores, dones, _ = env.step(np.asarray(actions))\n",
    "        indices = replay.add(\n",
    "            observations,\n",
    "            actions,\n",
    "            logs['is_exploration'],\n",
    "            next_observations,\n",
    "            delta_scores,\n",
    "            dones,\n",
    "            prev_indices=indices\n",
    "        )\n",
    "        observations = next_observations\n",
    "\n",
    "        if iteration >= prefill:\n",
    "            # Update the parameters of the GFlowNet\n",
    "            samples = replay.sample(batch_size=batch_size)\n",
    "            params, state, logs = gflownet.step(params, state, samples)\n",
    "\n",
    "            pbar.set_postfix(loss=f\"{logs['loss']:.2f}\", epsilon=f\"{epsilon:.2f}\")\n",
    "\n",
    "# Evaluate the posterior estimate\n",
    "posterior, _ = posterior_estimate(\n",
    "    gflownet,\n",
    "    params.online,\n",
    "    env,\n",
    "    key,\n",
    "    num_samples=1000,\n",
    "    desc='Sampling from posterior'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
